# llama2mlx
Karpathy's llama2.c transpiled to MLX for Apple Silicon

-- `huggingface-cli download --local-dir Llama-2-7b-chat-4-bit mlx-community/Llama-2-7b-chat-4-bit` to test
-- once PoC I will get this to be much better organized